# Train the model for 70-30 split
rf_model_70 = train_random_forest(X1_train, y1_train)


# Make predictions for 70-30 split
predictions_70 = make_predictions(rf_model_70, X1_test)


# Scatter plot of actual vs predicted values
plt.figure(figsize=(10, 6))
plt.scatter(y1_test, predictions_70, color='lightpink', alpha=0.6)

# Plot the line of perfect prediction (y = x)
plt.plot([y1_test.min(), y1_test.max()], [y1_test.min(), y1_test.max()], color='red', linestyle='--', label='Perfect Prediction')

plt.xlabel('Actual purchases')
plt.ylabel('Predicted purchases')
plt.title('Actual vs Predicted purchases - KNN Regressor(70-30 split)')
plt.legend()
plt.show()


# Evaluate the model's performance for 70-30 split
metrics_70 = evaluate_model(y1_test, predictions_70)

# Display the metrics
print("Metrics for 70-30 Split:")
print(metrics_70)


#Calculate the residuals for both splits
residuals_80 = y_test - y_pred_80
residuals_70 = y1_test - predictions_70

# Create side-by-side histograms to compare the residuals of both splits
plt.figure(figsize=(14, 6))

# Plot for 80-20 Split
plt.subplot(1, 2, 1)
sb.histplot(residuals_80, kde=True, color='pink', bins=20)
plt.title("Residuals (80-20 Split)")
plt.xlabel("Residuals")
plt.ylabel("Frequency")

# Plot for 70-30 Split
plt.subplot(1, 2, 2)
sb.histplot(residuals_70, kde=True, color='grey', bins=20)
plt.title("Residuals (70-30 Split)")
plt.xlabel("Residuals")
plt.ylabel("Frequency")

# Adjust layout and display the plots
plt.tight_layout()
plt.show()


